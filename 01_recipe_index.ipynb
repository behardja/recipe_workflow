{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b438eb60-6773-4c31-9342-461c2dd02e2f",
   "metadata": {},
   "source": [
    "# Recipe Vector Search Index Creation\n",
    "\n",
    "This notebook demonstrates how to create a vector search index for recipe similarity matching using Google Cloud Vertex AI. The process includes generating embeddings for recipes, creating a vector search index, and deploying it for real-time similarity queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ueyiz0uafwj",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "Import required libraries for data processing, Google Cloud services, and asynchronous operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86830307-b429-4de7-b238-b38240052a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from google.cloud import storage\n",
    "import asyncio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5rug378n7gw",
   "metadata": {},
   "source": [
    "## Project Configuration\n",
    "\n",
    "Set up project parameters including Google Cloud project ID, region, and storage bucket URIs for input and output data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646842e1-2e0b-4c7e-a8ed-56a98dadc318",
   "metadata": {},
   "source": [
    "## Cloud Storage Setup\n",
    "\n",
    "Create Google Cloud Storage buckets for storing recipe data and embeddings. This bucket will be used throughout the indexing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6ccf74c-a7d1-4f9e-91dc-01c13495035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"sandbox-401718\" # @param\n",
    "REGION = \"us-central1\" # @param\n",
    "INPUT_FILE = \"recipes_content.jsonl\" # @param\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}-recipe-textembedding-{REGION}\"\n",
    "INPUT_URI = f\"{BUCKET_URI}/input-test\"\n",
    "OUTPUT_URI = f\"{BUCKET_URI}/output-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "147233ab-799a-4a48-a6d9-df2f13dd1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f677773c-7c9e-41c0-b90b-6a945c86bda2",
   "metadata": {},
   "source": [
    "## Embedding Generation with Concurrent Processing\n",
    "\n",
    "Generate text embeddings for recipe content using Gemini's embedding model. This section implements asynchronous processing to handle large batches of recipes efficiently, significantly reducing processing time from sequential to concurrent execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4zsgqtymfds",
   "metadata": {},
   "source": [
    "### Initialize Gemini Client\n",
    "\n",
    "Set up the Gemini AI client for embedding generation with Vertex AI integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6eac45cd-ca64-4848-8a11-cbf71015fade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import EmbedContentConfig\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qds9rd8mikk",
   "metadata": {},
   "source": [
    "### Sample Data Generation (Optional)\n",
    "\n",
    "Commented code for creating sample recipe data if needed for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11e98c13-6cba-44a1-b42c-d9d8c3c4f469",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Create a dummy JSONL file\n",
    "# dummy_data = [\n",
    "#     {\"content\": \"Title:Miso-Butter Roast Chicken With Acorn Squash Panzanella,Ingredients:1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher salt...\"},\n",
    "#     {\"content\": \"Title:Classic Chocolate Chip Cookies,Ingredients:1 cup butter, 3/4 cup white sugar, 3/4 cup brown sugar, 2 eggs, 1 tsp vanilla...\"},\n",
    "#     {\"content\": \"Title:Spaghetti Carbonara,Ingredients:1 lb spaghetti, 2 large eggs, 1/2 cup grated Pecorino Romano cheese, 4 slices guanciale...\"},\n",
    "#     {\"content\": \"Title:Vegan Lentil Soup,Ingredients:1 tbsp olive oil, 1 large onion, 2 carrots, 2 celery stalks, 2 cloves garlic, 1 tsp dried thyme...\"},\n",
    "#     {\"content\": \"Title:Simple Guacamole,Ingredients:3 ripe avocados, 1/2 small onion, 1 lime, juiced, 1/2 tsp salt, 2 tbsp chopped cilantro...\"},\n",
    "# ]\n",
    "\n",
    "# INPUT_FILE = \"recipes.jsonl\"\n",
    "# with open(INPUT_FILE, \"w\") as f:\n",
    "#     for item in dummy_data:\n",
    "#         f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "# print(f\"Created '{INPUT_FILE}' with {len(dummy_data)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m2ryhi73nr",
   "metadata": {},
   "source": [
    "### Asynchronous Embedding Functions\n",
    "\n",
    "Define functions for concurrent embedding generation:\n",
    "- `embed_batch_sync()`: Synchronous function to embed a single batch\n",
    "- `main_async_runner()`: Main asynchronous coordinator that processes multiple batches concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "50e2d2d0-c886-4368-99aa-6befe1b8d21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "\n",
    "def embed_batch_sync(batch_of_content: list[str]) -> list[dict]:\n",
    "    \"\"\"\n",
    "    This is a standard SYNCHRONOUS function that embeds one batch.\n",
    "    It uses the exact API call structure that works in your environment.\n",
    "    \"\"\"\n",
    "    print(f\"Embedding a batch of {len(batch_of_content)} items...\")\n",
    "    try:\n",
    "        # This is the synchronous API call\n",
    "\n",
    "        response = client.models.embed_content(\n",
    "            model=\"gemini-embedding-001\",\n",
    "            contents=batch_of_content,\n",
    "            config=EmbedContentConfig(\n",
    "                output_dimensionality=3072,  # Optional\n",
    "                task_type=\"RETRIEVAL_DOCUMENT\",  # Optional\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        results = [\n",
    "            {\"content\": content, \"embedding\": embedding.values}\n",
    "            for content, embedding in zip(batch_of_content, response.embeddings)\n",
    "        ]\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with a batch: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "async def main_async_runner(input_file: str):\n",
    "    \"\"\"Main function to read the file and run synchronous jobs concurrently.\"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    tasks = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        content_batch = []\n",
    "        for line in f:\n",
    "            original_data = json.loads(line)\n",
    "            content_batch.append(original_data[\"content\"])\n",
    "\n",
    "            if len(content_batch) >= BATCH_SIZE:\n",
    "                # Use asyncio.to_thread to run the blocking function in a separate thread\n",
    "\n",
    "                task = asyncio.to_thread(embed_batch_sync, content_batch)\n",
    "                tasks.append(task)\n",
    "                content_batch = []\n",
    "    if content_batch:\n",
    "        task = asyncio.to_thread(embed_batch_sync, content_batch)\n",
    "        tasks.append(task)\n",
    "    print(f\"Created {len(tasks)} concurrent tasks.\")\n",
    "\n",
    "    # asyncio.gather will wait for all the threads to complete\n",
    "\n",
    "    all_batch_results = await asyncio.gather(*tasks)\n",
    "\n",
    "    final_results = [item for batch in all_batch_results for item in batch]\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"--- Process Finished ---\")\n",
    "    print(f\"Total time taken: {end_time - start_time:.2f} seconds\")\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5e7f9d8-125e-4ac6-87fe-c60555b7fff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 10 concurrent tasks.\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "Embedding a batch of 100 items...\n",
      "--- Process Finished ---\n",
      "Total time taken: 9.95 seconds\n",
      "\n",
      "Successfully generated 1000 embeddings.\n",
      "DataFrame with unique 'id' column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>embedding</th>\n",
       "      <th>embedding_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Title:Miso-Butter Roast Chicken With Acorn Squ...</td>\n",
       "      <td>[-0.0023760846816003323, -0.011549703776836395...</td>\n",
       "      <td>3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Title:Crispy Salt and Pepper Potatoes,Ingredie...</td>\n",
       "      <td>[0.01674710586667061, 0.010629256255924702, 0....</td>\n",
       "      <td>3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Title:Thanksgiving Mac and Cheese,Ingredients:...</td>\n",
       "      <td>[-0.0013591762399300933, -0.002013501012697816...</td>\n",
       "      <td>3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Title:Italian Sausage and Bread Stuffing,Ingre...</td>\n",
       "      <td>[0.006325311027467251, -0.005718541797250509, ...</td>\n",
       "      <td>3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Title:Newton's Law,Ingredients:1 teaspoon dark...</td>\n",
       "      <td>[0.011500250548124313, -0.005415198393166065, ...</td>\n",
       "      <td>3072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                            content  \\\n",
       "0  0  Title:Miso-Butter Roast Chicken With Acorn Squ...   \n",
       "1  1  Title:Crispy Salt and Pepper Potatoes,Ingredie...   \n",
       "2  2  Title:Thanksgiving Mac and Cheese,Ingredients:...   \n",
       "3  3  Title:Italian Sausage and Bread Stuffing,Ingre...   \n",
       "4  4  Title:Newton's Law,Ingredients:1 teaspoon dark...   \n",
       "\n",
       "                                           embedding  embedding_dim  \n",
       "0  [-0.0023760846816003323, -0.011549703776836395...           3072  \n",
       "1  [0.01674710586667061, 0.010629256255924702, 0....           3072  \n",
       "2  [-0.0013591762399300933, -0.002013501012697816...           3072  \n",
       "3  [0.006325311027467251, -0.005718541797250509, ...           3072  \n",
       "4  [0.011500250548124313, -0.005415198393166065, ...           3072  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the main asynchronous function\n",
    "all_embeddings = await main_async_runner(INPUT_FILE)\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame for easy analysis\n",
    "if all_embeddings:\n",
    "    df = pd.DataFrame(all_embeddings)\n",
    "    df['embedding_dim'] = df['embedding'].apply(len)\n",
    "    \n",
    "    print(f\"\\nSuccessfully generated {len(df)} embeddings.\")\n",
    "else:\n",
    "    print(\"\\nNo embeddings were generated. Please check for errors in the logs above.\")\n",
    "    \n",
    "    \n",
    "# Create a unique ID for each recipe using its index\n",
    "df['id'] = df.index.astype(str)\n",
    "\n",
    "# Reorder columns to have 'id' first for clarity\n",
    "df = df[['id', 'content', 'embedding', 'embedding_dim']]\n",
    "\n",
    "# Display the DataFrame with the new 'id' column\n",
    "print(\"DataFrame with unique 'id' column:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5f4816a-7a26-4f72-ad93-aac1b5328f4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"recipes_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bf5dc-6f72-4293-ba1c-c27b0fff4cff",
   "metadata": {},
   "source": [
    "## Vector Search Index Creation\n",
    "\n",
    "Create a vector search index for efficient similarity matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aj5a26hv8jd",
   "metadata": {},
   "source": [
    "### Prepare Index Data\n",
    "\n",
    "Format the embeddings data for Vertex AI Vector Search by creating JSONL format with ID and embedding pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fba2d42e-56c5-4074-8310-a66c5cb5a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data in the required JSONL format for Vertex AI Vector Search\n",
    "\n",
    "data_for_index = []\n",
    "for index, row in df.iterrows():\n",
    "    data_for_index.append({\n",
    "        \"id\": str(row['id']),\n",
    "        \"embedding\": row['embedding']\n",
    "    })\n",
    "\n",
    "# Define the output file name for the index data\n",
    "INDEX_DATA_FILE_NAME = \"recipes_index_data.json\"\n",
    "\n",
    "# Write the data to the JSONL file\n",
    "with open(INDEX_DATA_FILE_NAME, \"w\") as f:\n",
    "    for item in data_for_index:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bz7d4ipyau",
   "metadata": {},
   "source": [
    "### Upload to Cloud Storage\n",
    "\n",
    "Upload the prepared index data to Google Cloud Storage for use by the Vector Search service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b043ab4-7571-4067-8a1a-606bf948fd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'recipes_index_data.json' successfully uploaded to:\n",
      "gs://sandbox-401718-recipe-textembedding-us-central1/input-test/recipes_index_data.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize the GCS client. It will infer the project from your authenticated environment.\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Get the bucket name by simply removing the \"gs://\" prefix from your BUCKET_URI.\n",
    "bucket_name = BUCKET_URI.replace(\"gs://\", \"\")\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "# Get the destination folder path from the INPUT_URI variable.\n",
    "destination_folder = INPUT_URI.replace(BUCKET_URI, \"\").strip(\"/\")\n",
    "\n",
    "# Combine the folder path with the local filename to create the full blob name.\n",
    "# This will result in a path like \"input-test/recipes_index_data.jsonl\"\n",
    "destination_blob_name = f\"{destination_folder}/{INDEX_DATA_FILE_NAME}\"\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "# Upload the local file you just created.\n",
    "blob.upload_from_filename(INDEX_DATA_FILE_NAME)\n",
    "\n",
    "# Store the full GCS path of the uploaded file. This will now point to your INPUT_URI folder.\n",
    "index_data_gcs_uri = f\"gs://{bucket_name}/{destination_blob_name}\"\n",
    "\n",
    "print(f\"File '{INDEX_DATA_FILE_NAME}' successfully uploaded to:\")\n",
    "print(index_data_gcs_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b294d3f-85de-4cdb-8a13-122b6c803cce",
   "metadata": {},
   "source": [
    "## Create Vector Search Index\n",
    "\n",
    "Configure and create the vector search index using optimized distance metrics. The documentation recommends using `DOT_PRODUCT_DISTANCE` with `UNIT_L2_NORM` instead of `COSINE` distance for better performance while maintaining mathematical equivalence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kqlj5hkqjc",
   "metadata": {},
   "source": [
    "### Initialize AI Platform\n",
    "\n",
    "Set up Google Cloud AI Platform with project configuration and staging bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c8f4c434-d229-48d1-a572-e7ac24fe2d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=INPUT_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pbc1gtq5mgi",
   "metadata": {},
   "source": [
    "### Configure Index Parameters\n",
    "\n",
    "Set the embedding dimensions and display name for the vector search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d1cf183-bad0-4fd4-8b79-80b13bd95e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIMENSIONS = len(df[\"embedding\"][0])\n",
    "DISPLAY_NAME = \"index_recipe_match\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qd0e7ti6i0n",
   "metadata": {},
   "source": [
    "### Create the Index\n",
    "\n",
    "Create the Tree AH (Approximate Hierarchical) index with optimized distance measurement settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb6ec5f9-ee73-43bb-940e-70c92c4d518b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/757654702990/locations/us-central1/indexes/6928561527314186240/operations/1185869212346744832\n",
      "MatchingEngineIndex created. Resource name: projects/757654702990/locations/us-central1/indexes/6928561527314186240\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/757654702990/locations/us-central1/indexes/6928561527314186240')\n"
     ]
    }
   ],
   "source": [
    "ann_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    contents_delta_uri=f\"{INPUT_URI}\",\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=200,\n",
    "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    feature_norm_type=\"UNIT_L2_NORM\",\n",
    "    description=\"Similar Recipe match index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4cea42bb-7cc1-4712-a673-7decfdb10f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME = ann_index.resource_name #'projects/757654702990/locations/us-central1/indexes/9080369554546229248'\n",
    "\n",
    "ann_index = aiplatform.MatchingEngineIndex(\n",
    "    index_name=INDEX_RESOURCE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab8741-c465-49db-bb72-2748dc392563",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Index Deployment\n",
    "\n",
    "Deploy the created vector search index to an endpoint for real-time querying. This involves creating an index endpoint and deploying the index to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ilrce0xf3cj",
   "metadata": {},
   "source": [
    "### Create Index Endpoint\n",
    "\n",
    "Create a Matching Engine Index Endpoint that will host the deployed index for querying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "929d4ab7-7e97-4a67-a388-a9b0c85b3277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the project number\n",
    "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "# PROJECT_NUMBER = 757654702990\n",
    "\n",
    "VPC_NETWORK = \"beusebio-network\"\n",
    "VPC_NETWORK_FULL = f\"projects/{PROJECT_NUMBER}/global/networks/{VPC_NETWORK}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "51716746-b280-40f8-a482-de59a39a5936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/757654702990/locations/us-central1/indexEndpoints/3153243217810423808/operations/7168901317308448768\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/757654702990/locations/us-central1/indexEndpoints/3153243217810423808\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/757654702990/locations/us-central1/indexEndpoints/3153243217810423808')\n"
     ]
    }
   ],
   "source": [
    "# Endpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=\"index_endpoint_recipe\",\n",
    "    description=\"recipe index\",\n",
    "    network=VPC_NETWORK_FULL,\n",
    ")\n",
    "\n",
    "INDEX_ENDPOINT_NAME = my_index_endpoint.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "978983eb-44e8-440c-9244-3650ab196c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index.MatchingEngineIndex object at 0x7f22bd4a5a80> \n",
       "resource name: projects/757654702990/locations/us-central1/indexes/6928561527314186240"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ovusq546xhl",
   "metadata": {},
   "source": [
    "### Deploy Index to Endpoint\n",
    "\n",
    "Deploy the vector search index to the endpoint, making it available for similarity queries. The deployment creates the final infrastructure needed for recipe similarity matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc7ea969-76b5-44f1-9189-3e11b89b602c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/757654702990/locations/us-central1/indexEndpoints/3153243217810423808\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/757654702990/locations/us-central1/indexEndpoints/3153243217810423808/operations/7826426862904541184\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/757654702990/locations/us-central1/indexEndpoints/3153243217810423808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[id: \"recipe_index\"\n",
       "index: \"projects/757654702990/locations/us-central1/indexes/6928561527314186240\"\n",
       "create_time {\n",
       "  seconds: 1756927700\n",
       "  nanos: 743241000\n",
       "}\n",
       "private_endpoints {\n",
       "  match_grpc_address: \"10.116.0.14\"\n",
       "}\n",
       "index_sync_time {\n",
       "  seconds: 1756928971\n",
       "  nanos: 493166000\n",
       "}\n",
       "automatic_resources {\n",
       "  min_replica_count: 2\n",
       "  max_replica_count: 2\n",
       "}\n",
       "deployment_group: \"default\"\n",
       "]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy\n",
    "DEPLOYED_INDEX_ID = \"recipe_index\"\n",
    "my_index_endpoint = my_index_endpoint.deploy_index(\n",
    "    index=ann_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
    ")\n",
    "\n",
    "my_index_endpoint.deployed_indexes"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m117",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m117"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
